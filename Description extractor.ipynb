{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport re\nimport csv\nimport codecs",
      "metadata": {},
      "execution_count": 4,
      "outputs": [],
      "id": "43537640"
    },
    {
      "cell_type": "code",
      "source": "# Load and format the external datasets\nfor i in range(1, 7):\n    filename = f'books_with_description{i}.csv'\n    locals()[\"df\" + str(i)] = pd.read_csv(filename)\n\n# Format for each dataset\ndf_ext1 = df1[['book_isbn', 'book_desc']]\ndf_ext1 = df_ext1.rename(columns={'book_isbn': 'isbn'})\ndf_ext1 = df_ext1.rename(columns={'book_desc': 'description'})\ndf_ext1['isbn'] = df_ext1['isbn'].astype(str)\ndf_ext1['isbn'] = df_ext1['isbn'].str.replace('13:', '')\ndf_ext1['isbn'] = df_ext1['isbn'].apply(lambda x: '{:.0f}'.format(float(x)) if 'E' in x else x.ljust(13, '0'))\n\ndf_ext2 = df2[['isbn13', 'description']]\ndf_ext2 = df_ext2.rename(columns={'isbn13': 'isbn'})\ndf_ext2['isbn'] = df_ext2['isbn'].astype(str)\ndf_ext2['isbn'] = df_ext2['isbn'].str.replace(r'\\.0$', '', regex=True)\n\ndf_ext3 = df3[['isbn13', 'description']]\ndf_ext3 = df_ext3.rename(columns={'isbn13': 'isbn'})\ndf_ext3['isbn'] = df_ext3['isbn'].astype(str)\ndf_ext3['isbn'] = df_ext3['isbn'].str.replace(r'\\.0$', '', regex=True)\n\ndf_ext4 = df4[['isbn', 'description']]\ndf_ext4['isbn'] = df_ext4['isbn'].astype(str)\ndf_ext4 = df_ext4[df_ext4['isbn'].str.contains(r'^[eE]+$')]\ndf_ext4['isbn'] = df_ext4['isbn'].apply(lambda x: '{:.0f}'.format(float(x)) if 'E' in x else x.ljust(13, '0'))\n\ndf_ext5 = df5[['isbn13', 'description']]\ndf_ext5 = df_ext5.rename(columns={'isbn13': 'isbn'})\ndf_ext5['isbn'] = df_ext5['isbn'].astype(str)\ndf_ext5['isbn'] = df_ext5['isbn'].str.replace(r'\\.0$', '', regex=True)\n\ndf_ext6 = df6[['isbn', 'description']]\ndf_ext6['isbn'] = df_ext6['isbn'].astype(str)\ndf_ext6['isbn'] = df_ext6['isbn'].str.replace('13:', '')\ndf_ext6 = df_ext6[df_ext6['isbn'].str.contains(r'^[eE]+$')]\ndf_ext6['isbn'] = df_ext6['isbn'].apply(lambda x: '{:.0f}'.format(float(x)) if 'E' in x else x.ljust(13, '0'))\n\n# Join and clean dataframes\ncombined_df = pd.concat([df_ext1, df_ext2, df_ext3, df_ext4, df_ext5, df_ext6])\ncombined_df['isbn'] = combined_df['isbn'].replace('nan', np.nan)\ncombined_df = combined_df.dropna()\ncombined_df = combined_df.drop_duplicates(subset='isbn')\ncombined_df['isbn'] = combined_df['isbn'].str.replace('X', '10')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "36d3125a"
    },
    {
      "cell_type": "code",
      "source": "# Fix manually the broken format in the delivered file\nwith open('books.csv', 'rb') as input_file:\n\n    decoder = codecs.iterdecode(input_file, 'utf-8', errors='replace')\n    reader = csv.reader(decoder)\n    rows = []\n    \n    # Modify the broken rows\n    for i, row in enumerate(reader):\n        if i == 3349:\n            row[2] = \"Sam Bass Warner Jr./Sam B. Warner\"\n            row[3] = \"3.58\"\n            row[4] = \"0674842111\"\n            row[5] = \"9780674842113\"\n            row[6] = \"en-US\"\n            row[7] = \"236\"\n            row[8] = \"61\"\n            row[9] = \"6\"\n            row[10] = \"4/20/2004\"\n            row[11] = \"Harvard University Press\"\n            del row[12] \n        if i == 4703:\n            row[2] = \"David E. Smith\"\n            row[3] = \"3.58\"\n            row[4] = \"1593600119\"\n            row[5] = \"9781593600112\"\n            row[6] = \"eng\"\n            row[7] = \"400\"\n            row[8] = \"26\"\n            row[9] = \"4\"\n            row[10] = \"4/6/2004\"\n            row[11] = \"Cold Spring Press\"\n            del row[12] \n        if i == 5878:\n            row[2] = \"James Wesley Rawles\"\n            row[3] = \"3.63\"\n            row[4] = \"156384155X\"\n            row[5] = \"9781563841552\"\n            row[6] = \"eng\"\n            row[7] = \"342\"\n            row[8] = \"38\"\n            row[9] = \"4\"\n            row[10] = \"1/15/1999\"\n            row[11] = \"Huntington House Publishers\"\n            del row[12] \n        if i == 8980:\n            row[2] = \"Brown Son & Ferguson\"\n            row[3] = \"0.00\"\n            row[4] = \"0851742718\"\n            row[5] = \"9780851742717\"\n            row[6] = \"eng\"\n            row[7] = \"49\"\n            row[8] = \"0\"\n            row[9] = \"0\"\n            row[10] = \"5/1/1977\"\n            row[11] = \"Brown Son & Ferguson Ltd.\"\n            del row[12] \n\n        # Append the row to the list\n        rows.append(row)\n\n# Open the output CSV file\nwith open('books_clean.csv', 'w', newline='', encoding='utf-8') as output_file:\n    # Create a CSV writer object\n    writer = csv.writer(output_file)\n    \n    # Write the modified rows to the output file\n    writer.writerows(rows)",
      "metadata": {},
      "execution_count": 48,
      "outputs": [],
      "id": "af6e04a3"
    },
    {
      "cell_type": "code",
      "source": "# Load and transform the delivered dataset\ndf = pd.read_csv('books_clean.csv')\ndf_imp = df[['isbn13', 'title', 'authors', 'publisher', 'average_rating']]\ndf_imp = df_imp.rename(columns={'isbn13': 'isbn'})\ndf_imp = df_imp.rename(columns={'authors': 'writer'})\ndf_imp = df_imp.rename(columns={'average_rating': 'avg_score'})\ndf_imp['isbn'] = df_imp['isbn'].astype(str).str.rstrip('.0').str.ljust(13, '0')\ndf_imp['isbn'] = df_imp['isbn'].str.replace('X', '10')\n\n# Save the transformed set for direct database import\ndf_imp.to_csv('books_import.csv', index=False)",
      "metadata": {},
      "execution_count": 112,
      "outputs": [],
      "id": "bbaa5eb3"
    },
    {
      "cell_type": "code",
      "source": "# Intersection between the delivered and the scraped dataset\nmerged_df = pd.merge(combined_df, df_imp, on='isbn', how='inner')\nbook_desc_df = merged_df[['isbn', 'description']]\n\nprint(\"Number of matching books found:\", len(book_desc_df), \" of \", len(df_imp))",
      "metadata": {},
      "execution_count": 113,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Number of matching books found: 8842  of  11127\n"
        }
      ],
      "id": "88c7c87b"
    },
    {
      "cell_type": "code",
      "source": "# Save the final reduced description dataset\nbook_desc_df.to_csv('books_descriptions.csv', index=False)",
      "metadata": {},
      "execution_count": 114,
      "outputs": [],
      "id": "fc506a13"
    },
    {
      "cell_type": "code",
      "source": "# Display the total number of unique descriptions found\nlen(combined_df)",
      "metadata": {},
      "execution_count": 115,
      "outputs": [
        {
          "execution_count": 115,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1045834"
            ]
          },
          "metadata": {}
        }
      ],
      "id": "599d3aa0"
    }
  ]
}